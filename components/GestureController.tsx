// src/components/GestureController.tsx

import React, { useEffect, useRef, useState, useCallback } from 'react';
import { FilesetResolver, HandLandmarker, DrawingUtils } from '@mediapipe/tasks-vision';
import { TreeMode } from '../types'; // ç¡®ä¿è·¯å¾„æ­£ç¡®

interface GestureControllerProps {
  onModeChange: (mode: TreeMode) => void;
  currentMode: TreeMode;
  onHandPosition?: (x: number, y: number, detected: boolean) => void;
}

export const GestureController: React.FC<GestureControllerProps> = ({ 
  onModeChange, 
  currentMode, 
  onHandPosition 
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [gestureStatus, setGestureStatus] = useState<string>("Initializing...");
  const [handDetected, setHandDetected] = useState(false);
  
  // ä½¿ç”¨ useRef æ¥æŒæœ‰ HandLandmarker å®ä¾‹å’Œ requestAnimationFrame ID
  const handLandmarkerRef = useRef<HandLandmarker | null>(null);
  const animationFrameIdRef = useRef<number | null>(null); // å·²ä¿®æ­£ç±»å‹

  // ç”¨äºæ‰‹åŠ¿è¯†åˆ«çš„å¸§è®¡æ•°å™¨
  const openFrames = useRef(0);
  const closedFrames = useRef(0);
  const CONFIDENCE_THRESHOLD = 5;

  // !!! å…³é”®ä¿®æ­£ !!!
  // modeRef ç”¨äºåœ¨ `predictWebcam` ç­‰ useCallback å‡½æ•°ä¸­è®¿é—® `currentMode` çš„æœ€æ–°å€¼
  const modeRef = useRef(currentMode);
  useEffect(() => {
    modeRef.current = currentMode;
  }, [currentMode]);

  // `predictWebcam` å‡½æ•°ï¼šå¤„ç†æ¯ä¸€å¸§çš„è§†é¢‘æ•°æ®å¹¶è¿›è¡Œæ‰‹åŠ¿è¯†åˆ«
  // ä¾èµ–é¡¹åªåŒ…æ‹¬ç¨³å®šçš„ `onModeChange` å’Œ `onHandPosition`
  const predictWebcam = useCallback(async () => {
    // console.log("Inside predictWebcam function."); // è°ƒè¯•æ—¶å¯ä»¥å¼€å¯

    const videoElement = videoRef.current;
    const landmarker = handLandmarkerRef.current;
    const canvasElement = canvasRef.current;

    // å¦‚æœä»»ä½•å¿…è¦å…ƒç´ ä¸å¯ç”¨ï¼Œåˆ™ç»§ç»­è¯·æ±‚ä¸‹ä¸€å¸§ï¼Œç›´åˆ°å¯ç”¨
    if (!videoElement || !landmarker || videoElement.readyState < 2 || !canvasElement) {
      animationFrameIdRef.current = requestAnimationFrame(predictWebcam); 
      return;
    }

    const canvasCtx = canvasElement.getContext("2d");
    if (!canvasCtx) {
      console.error("Could not get 2D context for canvas.");
      animationFrameIdRef.current = requestAnimationFrame(predictWebcam);
      return;
    }

    // è°ƒæ•´ canvas å°ºå¯¸ä»¥åŒ¹é…è§†é¢‘å°ºå¯¸ï¼Œç¡®ä¿ç»˜åˆ¶å‡†ç¡®
    canvasElement.width = videoElement.videoWidth;
    canvasElement.height = videoElement.videoHeight;
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height); // æ¸…é™¤ä¸Šä¸€å¸§çš„ç»˜åˆ¶

    try {
      const results = await landmarker.detectForVideo(videoElement, Date.now());

      if (results.landmarks && results.landmarks.length > 0) {
        setHandDetected(true);
        const drawingUtils = new DrawingUtils(canvasCtx);

        for (const landmarks of results.landmarks) {
          drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 5 });
          drawingUtils.drawLandmarks(landmarks, { color: '#FF0000', lineWidth: 2 });
        }

        const landmarks = results.landmarks[0];
        let centerX = 0;
        let centerY = 0;
        for (const landmark of landmarks) {
          centerX += landmark.x;
          centerY += landmark.y;
        }
        centerX /= landmarks.length;
        centerY /= landmarks.length;

        if (onHandPosition) {
          onHandPosition(centerX, centerY, true);
        }

        // æ‰‹åŠ¿è¯†åˆ«é€»è¾‘
        const indexTip = landmarks[8];
        const indexPIP = landmarks[6];
        const middleTip = landmarks[12];
        const middlePIP = landmarks[10];

        const indexOpen = indexTip.y < indexPIP.y;
        const middleOpen = middleTip.y < middlePIP.y;

        if (indexOpen && middleOpen) {
          openFrames.current++;
          closedFrames.current = 0;

          // é€šè¿‡ modeRef.current è®¿é—®æœ€æ–°çš„ currentMode
          if (openFrames.current > CONFIDENCE_THRESHOLD && modeRef.current === TreeMode.FORMED) {
            onModeChange(TreeMode.CHAOS);
            setGestureStatus("âœ¨ CHAOS MODE âœ¨");
            console.log("Switching to CHAOS mode!");
            openFrames.current = 0;
          }
        } else {
          closedFrames.current++;
          openFrames.current = 0;

          // é€šè¿‡ modeRef.current è®¿é—®æœ€æ–°çš„ currentMode
          if (closedFrames.current > CONFIDENCE_THRESHOLD && modeRef.current === TreeMode.CHAOS) {
            onModeChange(TreeMode.FORMED);
            setGestureStatus("ğŸ„ FORMED MODE ğŸ„");
            console.log("Switching to FORMED mode!");
            closedFrames.current = 0;
          }
        }
      } else {
        setHandDetected(false);
        if (onHandPosition) {
          onHandPosition(0.5, 0.5, false);
        }
        setGestureStatus("No hand detected - Show your hand");
        openFrames.current = 0;
        closedFrames.current = 0;
        
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      }
    } catch (error) {
      console.error("Prediction error:", error);
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    }

    // å¸§ç‡é™åˆ¶ï¼šä½¿ç”¨ setTimeout æ›¿ä»£ç›´æ¥çš„ requestAnimationFrame
    setTimeout(() => {
      animationFrameIdRef.current = requestAnimationFrame(predictWebcam); 
    }, 60); 
  }, [onModeChange, onHandPosition]); // å…³é”®ä¿®æ­£ï¼šç§»é™¤ currentMode ä¾èµ–

// src/components/GestureController.tsx - startWebcam å‡½æ•°

// `startWebcam` å‡½æ•°ï¼šè´Ÿè´£è·å–æ‘„åƒå¤´è§†é¢‘æµå¹¶å¯åŠ¨ MediaPipe é¢„æµ‹å¾ªç¯
  // ä¾èµ–é¡¹æ˜¯ predictWebcamï¼Œè¿™æ˜¯æ­£ç¡®çš„ã€‚
  const startWebcam = useCallback(async () => {
    console.log("Attempting to start webcam..."); 
    try {
      if (!navigator.mediaDevices?.getUserMedia) {
        setGestureStatus("Webcam not supported by browser");
        console.log("Webcam not supported.");
        return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 320, height: 240, facingMode: "user" }
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        console.log("Webcam stream assigned to video element.");
        
        await videoRef.current.play(); 
        console.log("Video element play() called and awaited.");

        // !!! å…³é”®ä¿®æ­£ï¼šåœ¨æ·»åŠ äº‹ä»¶ç›‘å¬å™¨ä¹‹å‰æ£€æŸ¥ readyState !!!
        if (videoRef.current.readyState >= 2) { // 2 = HAVE_CURRENT_DATA æˆ–æ›´é«˜ (æ•°æ®å·²åŠ è½½è¶³ä»¥æ’­æ”¾)
          console.log("Video already loaded. Starting MediaPipe prediction directly.");
          predictWebcam(); // ç›´æ¥å¯åŠ¨é¢„æµ‹
        } else {
          console.log("Video not yet loaded. Adding loadeddata event listener.");
          videoRef.current.addEventListener("loadeddata", () => {
            console.log("Webcam video loaded and playing. Starting MediaPipe prediction...");
            predictWebcam(); // äº‹ä»¶è§¦å‘æ—¶å¯åŠ¨é¢„æµ‹
          }, { once: true });
        }
        
        setGestureStatus("Ready - Show your hand");
        console.log("Gesture status set to Ready.");
      } else {
        console.log("Video ref current is null, cannot start webcam.");
      }
    } catch (err: any) {
      console.error("Webcam error:", err);
      if (err.name === 'NotAllowedError') {
        setGestureStatus("Please allow camera access");
      } else {
        setGestureStatus(`Webcam error: ${err.message || err.name}`);
      }
    }
  }, [predictWebcam]); // ä¾èµ–é¡¹ä¾ç„¶æ˜¯ predictWebcam


  // `useEffect` é’©å­ï¼šä»…åœ¨ç»„ä»¶é¦–æ¬¡æŒ‚è½½æ—¶åˆå§‹åŒ– MediaPipe å’Œæ‘„åƒå¤´
  useEffect(() => {
    const setup = async () => {
      // ä»…å½“ handLandmarker å°šæœªåˆå§‹åŒ–æ—¶æ‰æ‰§è¡Œ
      if (!handLandmarkerRef.current) { 
        try {
          console.log("Initializing MediaPipe HandLandmarker...");

          const vision = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm"
          );

          handLandmarkerRef.current = await HandLandmarker.createFromOptions(vision, {
            baseOptions: {
              modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
              delegate: "GPU"
            },
            runningMode: "VIDEO",
            numHands: 1
          });

          console.log("MediaPipe HandLandmarker initialized successfully!");
          startWebcam(); // MediaPipe åˆå§‹åŒ–æˆåŠŸåæ‰å¯åŠ¨æ‘„åƒå¤´
          console.log("setup() finished, startWebcam called.");
        } catch (error) {
          console.error("Error initializing MediaPipe:", error);
          setGestureStatus("Hand detection unavailable due to MediaPipe error");
          handLandmarkerRef.current = null;
        }
      } else {
        console.log("MediaPipe HandLandmarker already initialized, skipping setup.");
      }
    };

    setup(); 

    // æ¸…ç†å‡½æ•°ï¼šåœ¨ç»„ä»¶å¸è½½æ—¶é‡Šæ”¾æ‰€æœ‰èµ„æº
    return () => {
      console.log("Cleaning up GestureController...");
      if (animationFrameIdRef.current) {
        cancelAnimationFrame(animationFrameIdRef.current);
      }
      if (handLandmarkerRef.current) {
        handLandmarkerRef.current.close();
        handLandmarkerRef.current = null;
        console.log("MediaPipe HandLandmarker closed.");
      }
      if (videoRef.current?.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
        videoRef.current.srcObject = null;
        console.log("Webcam stream stopped.");
      }
    };
  }, [startWebcam]); // ä¾èµ– startWebcam

  console.log("GestureController rendered ğŸŸ¢");
  console.log("HandLandmarker status:", handLandmarkerRef.current);

  return (
    <div className="fixed top-4 right-4 z-[9999] w-80
      bg-black/70 border border-[#D4AF37] p-3 rounded-lg
      pointer-events-auto shadow-[0_0_20px_#D4AF37]">

      <div className="relative mb-3 bg-black rounded overflow-hidden">
        <video
          ref={videoRef}
          width={320}
          height={240}
          className="w-full aspect-video object-cover"
          playsInline
          muted
          autoPlay
        />
        <canvas
          ref={canvasRef}
          width={320}
          height={240}
          className="absolute top-0 left-0 w-full h-full object-contain pointer-events-none"
        />
        <div className={`absolute top-2 left-2 text-xs px-2 py-1 rounded font-bold ${handDetected ? 'bg-green-500/70' : 'bg-red-500/70'}`}>
          {handDetected ? 'âœ“ æ‰‹å·²æ£€æµ‹' : 'âœ— æœªæ£€æµ‹'}
        </div>
      </div>

      <div className="text-center text-[#D4AF37] font-serif text-sm">
        <p className="font-bold mb-1">{gestureStatus}</p>
        <div className="text-xs opacity-70 space-y-1">
          <p>å¼ å¼€æ‰‹æŒ‡ â†’ CHAOS ğŸŒªï¸</p>
          <p>æ¡æ‹³ â†’ FORMED ğŸ„</p>
        </div>
      </div>
    </div>
  );
};
